{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiftiDataset(Dataset):\n",
    "    def __init__(self, source_dir, target_dir, transforms):\n",
    "        \"\"\"\n",
    "        create a dataset in PyTorch for reading NIfTI files\n",
    "        Args:\n",
    "            source_dir (str): path to source images\n",
    "            target_dir (str): path to target images\n",
    "            transform (callable) transform to apply to both source and target images\n",
    "        \"\"\"\n",
    "        self.source_dir = source_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transforms\n",
    "        self.source_images = NiftiDataset.get_data_paths(source_dir)\n",
    "        self.target_images = NiftiDataset.change_path_for_targets(self.source_images)\n",
    "        \n",
    "    def get_data_paths(directory):\n",
    "        paths = []\n",
    "        for i in os.listdir(directory):\n",
    "            paths.append(os.path.join(directory, i))\n",
    "        return paths\n",
    "    \n",
    "    def change_path_for_targets(source_images):\n",
    "        target_images = []\n",
    "        for i in source_images:\n",
    "            mapped_string = i.replace(\"t1\", \"t2\")\n",
    "            mapped_string = mapped_string.replace(\"T1_fcm\",\"T2_reg_fcm\" )\n",
    "            target_images.append(mapped_string)\n",
    "        return target_images\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.source_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source_image = nib.load(self.source_images[idx]).get_fdata()\n",
    "        target_image = nib.load(self.target_images[idx]).get_fdata()\n",
    "        source_patch, target_patch = self.transform(source_image, target_image)\n",
    "\n",
    "        return np.transpose(source_patch, (1, 0, 2)), np.transpose(target_patch, (1, 0, 2))\n",
    "    \n",
    "class RandomCrop3D:\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def generate_patch(self, source, target):\n",
    "        if isinstance(self.output_size, int):\n",
    "            crop_start_x = np.random.randint(0, source.shape[0] - self.output_size + 1)\n",
    "            crop_start_y = np.random.randint(0, source.shape[2] - self.output_size + 1)\n",
    "            crop_end_x = crop_start_x + self.output_size\n",
    "            crop_end_y = crop_start_y + self.output_size\n",
    "\n",
    "            return (source[crop_start_x:crop_end_x, :, crop_start_y: crop_end_y],\n",
    "                   target[crop_start_x:crop_end_x, :, crop_start_y: crop_end_y])\n",
    "        \n",
    "        if isinstance(self.output_size, tuple):\n",
    "            crop_start_x = np.random.randint(0, source.shape[0] - self.output_size[0] + 1)\n",
    "            crop_start_y = np.random.randint(0, source.shape[2] - self.output_size[1] + 1)\n",
    "            crop_end_x = crop_start_x + self.output_size[0]\n",
    "            crop_end_y = crop_start_y + self.output_size[1]\n",
    "\n",
    "            return (source[crop_start_x:crop_end_x, :, crop_start_y: crop_end_y],\n",
    "                   target[crop_start_x:crop_end_x, :, crop_start_y: crop_end_y])\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "                        torch.nn.Conv3d(120, 240, 3, 1, 1),\n",
    "                        torch.nn.BatchNorm3d(240),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Conv3d(240, 240, 3, 1, 1),\n",
    "                        torch.nn.BatchNorm3d(240),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Conv3d(240, 120, 3, 1, 1),\n",
    "                                         )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = RandomCrop3D(65)\n",
    "df = NiftiDataset(\"../small_data/small/t1/\", \"../small_data/small/t2/\", rand.generate_patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = torch.utils.data.random_split(df, [17, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-5)\n",
    "criterion = torch.nn.MSELoss()\n",
    "train_loader = DataLoader(train_data, batch_size=48)\n",
    "test_loader = DataLoader(test_data, batch_size=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train Loss: 0.535723865032196, Test Loss: 0.6659237146377563\n",
      "Epoch: 20, Train Loss: 0.3057956099510193, Test Loss: 0.525753378868103\n",
      "Epoch: 30, Train Loss: 0.2300391048192978, Test Loss: 0.40821942687034607\n",
      "Epoch: 40, Train Loss: 0.2193366140127182, Test Loss: 0.2777760922908783\n",
      "Epoch: 50, Train Loss: 0.2065686583518982, Test Loss: 0.22226104140281677\n",
      "Epoch: 60, Train Loss: 0.2040197104215622, Test Loss: 0.18528293073177338\n",
      "Epoch: 70, Train Loss: 0.1952318698167801, Test Loss: 0.18756912648677826\n",
      "Epoch: 80, Train Loss: 0.184870645403862, Test Loss: 0.17772535979747772\n",
      "Epoch: 90, Train Loss: 0.17650218307971954, Test Loss: 0.17603114247322083\n"
     ]
    }
   ],
   "source": [
    "for t in range(1, 100):\n",
    "    model.train()\n",
    "    for i, (src, tgt) in enumerate(train_loader):\n",
    "        src.unsqueeze_(-1)\n",
    "        tgt.unsqueeze_(-1)\n",
    "        src, tgt = src.to(device).float(), tgt.to(device).float()\n",
    "        pred = model(src)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(pred, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (src, tgt) in test_loader:\n",
    "            src.unsqueeze_(-1)\n",
    "            tgt.unsqueeze_(-1)\n",
    "            src, tgt = src.to(device).float(), tgt.to(device).float()\n",
    "            pred = model(src)\n",
    "            test_loss = criterion(pred, tgt)\n",
    "    if t % 10 == 0:\n",
    "        print(f'Epoch: {t}, Train Loss: {loss}, Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Medical",
   "language": "python",
   "name": "medical"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
